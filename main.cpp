/*
Для выполнения практических заданий используются суперкомпьютерные вычислительные ресурсы факультета ВМК - Bluegene/P и Polus.
http://hpc.cs.msu.ru/

В каждой задаче требуется:
1) Реализовать параллельную версию предложенного алгоритма с использованием технологий OpenMP и MPI.
2) Начальные параметры для задачи подбираются таким образом, чтобы:
- Задача помещалась в оперативную память одного процессора.
- Время решения задачи было в примерном диапазоне 5 сек.-15 минут.
3) Исследовать масштабируемость полученной параллельной программы: построить графики зависимости времени исполнения от числа ядер/процессоров для различного объёма входных данных.
Для каждого набора входных данных найти количество ядер/процессоров, при котором время выполнения задачи перестаёт уменьшаться.
Оптимальным является построение трёхмерного графика: по одной из осей время работы программы, по другой - количество ядер/процессоров и по третьей - объём входных данных.
Каждый прогон программы с новыми параметрами рекомендуется выполнять несколько раз с последующим усреднением результата (для избавления от случайных выбросов).
Для замера времени рекомендуется использовать вызовы функции omp_get_wtime или MPI_Wtime, общее время работы должно определяться временем самого медленного из процессов/нитей.
Количество ядер/процессоров рекомендуется задавать в виде p=2n, n=0, 1, 2, ... , k, где k определяется доступными ресурсами.
4) Определить основные причины недостаточной масштабируемости программы при максимальном числе используемых ядер/процессоров.
5) Сравнить эффективность OpenMP и MPI-версий параллельной программы.
6) Подготовить отчет о выполнении задания, включающий: описание реализованного алгоритма, графики зависимости времени исполнения от числа ядер/процессоров для различного объёма входных данных, текст программы.
*/

#include <iostream>
#include <omp.h>
#include <vector>
#include <unistd.h>

#include "utils.h"
#include "transpose_openmp.h"

using std::cout;
using std::vector;
using namespace NMatrix;


int main(int argc, char* argv[]) {
    #ifdef _OPENMP
        printf("OpenMP is supported! %d \n\n", _OPENMP);
    #endif

    int w, t, i;

    sscanf(argv[1], "%d", &w);
    sscanf(argv[2], "%d", &t);
    sscanf(argv[3], "%d", &i);

    vector<int> thread_num = {1, 2, 4, 8, 16, 32, 64, 128};
    vector<int> widths = {17000, 20000, 23000, 25000, 28000, 30000, 32000, 35000, 40000, 50000, 60000};

    for (; w < widths.size(); ++w) {
        for (; t < thread_num.size(); ++t) {
            for (; i < 13; ++i) {
                FILE* fout = fopen("log", "a");
		FILE* log = fopen("tmp_log", "a");
		fprintf(log, "%d %d %d\n", w, t, i);
		fclose(log);
                int width = widths[w];
                int threads = thread_num[t];
                omp_set_num_threads(threads);
                fprintf(fout, "%d, %d, %d,", i, width, threads);
                fclose(fout);
                long double openmp_time =  measureTimeOfTranspose(
                    transpose_OpenMP,
                    {width, width}
                );
                fout = fopen("log", "a");
                fprintf(fout, " %.3Lf\n", openmp_time * 1000);
                fclose(fout);
	    }
	    i = 0;
        }
        t = 0;
    }
    FILE* log = fopen("tmp_log", "a");
    fprintf(log, "END!");
    fclose(log);
    return 0;
}
